{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "218ba7f2",
   "metadata": {},
   "source": [
    "# Importing Packages\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fcd0faa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "# 1. Imports and Seed Setup\n",
    "# -----------------------------\n",
    "\n",
    "# Standard library\n",
    "import os\n",
    "import glob\n",
    "import math\n",
    "import re\n",
    "import shutil\n",
    "import time\n",
    "import json\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "\n",
    "# Third-party\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "import joblib\n",
    "\n",
    "# PyTorch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.backends.cudnn as cudnn\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "\n",
    "# PyTorch Geometric\n",
    "from torch_geometric.data import Data, Batch\n",
    "from torch_geometric.loader import DataLoader as PyGDataLoader\n",
    "from torch_geometric.nn import EdgeConv, knn_graph, global_max_pool\n",
    "\n",
    "\n",
    "# PyTorch Ignite\n",
    "from ignite.engine import Engine, Events\n",
    "from ignite.metrics import Loss\n",
    "from ignite.metrics.metric import Metric\n",
    "from ignite.handlers import ModelCheckpoint, EarlyStopping\n",
    "from ignite.contrib.handlers import ProgressBar\n",
    "from ignite.contrib.handlers.tensorboard_logger import TensorboardLogger\n",
    "\n",
    "# Warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Reproducibility\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "cudnn.deterministic = True\n",
    "cudnn.benchmark = False\n",
    "\n",
    "\n",
    "print(torch.__version__)     # e.g., 2.1.0\n",
    "print(torch.version.cuda) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f71c1d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "# PyG Extension Sanity Check\n",
    "# -----------------------------\n",
    "try:\n",
    "    import torch_scatter\n",
    "    import torch_sparse\n",
    "    import torch_cluster\n",
    "    import torch_spline_conv\n",
    "    from torch_geometric.nn import knn_graph\n",
    "\n",
    "    # Create dummy inputs\n",
    "    x = torch.randn(32, 3).cuda()  # 32 3D points\n",
    "    batch = torch.zeros(32, dtype=torch.long).cuda()\n",
    "    edge_index = knn_graph(x, k=4, batch=batch)\n",
    "\n",
    "    print(\"✅ PyG extensions loaded and working.\")\n",
    "except ImportError as e:\n",
    "    print(\"❌ PyG Import Error:\", e)\n",
    "except Exception as e:\n",
    "    print(\"❌ PyG Runtime Error:\", e)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15e54c9f",
   "metadata": {},
   "source": [
    "# EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "951a8a0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = Path(\"..\") / \"dataset\" / \"raw\" / \"DrivAerNetPlusPlus_Drag_8k_cleaned.csv\"\n",
    "df = pd.read_csv(file_path)\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c14b960c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# Check if CUDA is available\n",
    "print(\"CUDA Available:\", torch.cuda.is_available())\n",
    "\n",
    "# Get current device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "# Print GPU name\n",
    "if torch.cuda.is_available():\n",
    "    print(\"GPU Name:\", torch.cuda.get_device_name(0))\n",
    "    print(\"Memory Allocated:\", torch.cuda.memory_allocated(0) / 1024**2, \"MB\")\n",
    "    print(\"Memory Cached:\", torch.cuda.memory_reserved(0) / 1024**2, \"MB\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7fe6b21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the pdf graph for Average Drag Coefficient (Cd)\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.histplot(df['Average Cd'], bins=30, kde=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41516c9c",
   "metadata": {},
   "source": [
    "# Pepraring Scaler Function and Global variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1a83241",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "# 1.2. Prepaing Scaler\n",
    "# -----------------------------\n",
    "\n",
    "# Base path\n",
    "base_path = Path(\"..\") / \"dataset\"\n",
    "\n",
    "# Subset to only training car IDs\n",
    "train_ids_path = base_path / \"raw\" / \"subset_dir\" / \"train_design_ids.txt\"\n",
    "with open(train_ids_path) as f:\n",
    "    train_ids = [line.strip() for line in f]\n",
    "\n",
    "df_train = df[df[\"Design\"].isin(train_ids)]\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(df_train[[\"Average Cd\"]])\n",
    "\n",
    "print(f\"Scaler mean: {scaler.mean_[0]:.6f}, std: {scaler.scale_[0]:.6f}\")\n",
    "\n",
    "# Save scaler to disk\n",
    "scaler_dir = base_path / \"scaler\"\n",
    "scaler_dir.mkdir(parents=True, exist_ok=True)\n",
    "joblib.dump(scaler, scaler_dir / \"cd_scaler.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70da915d",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f350841",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ###################################\n",
    "# Minimal EdgeConv Slice Encoder (Replaces PointNet2D)\n",
    "# ###################################\n",
    "class EdgeConvSliceEncoder(nn.Module):\n",
    "    \"\"\"\n",
    "    Encodes a batch of 2D slices, each with a variable number of points,\n",
    "    into a fixed-size embedding vector for each slice.\n",
    "    This module is designed to work with PyTorch Geometric's Batch object.\n",
    "    \"\"\"\n",
    "    def __init__(self, input_dim=2, emb_dim=256, k=20):\n",
    "        super().__init__()\n",
    "        self.k = k\n",
    "\n",
    "        # Define the MLP that will be used inside EdgeConv\n",
    "        # It processes concatenated features of a point and its neighbors\n",
    "        mlp = nn.Sequential(\n",
    "            nn.Linear(2 * input_dim, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, emb_dim) # Output the final embedding dimension\n",
    "        )\n",
    "\n",
    "        # The EdgeConv layer itself\n",
    "        self.edge_conv = EdgeConv(nn=mlp, aggr='max')\n",
    "\n",
    "    def forward(self, data):\n",
    "        \"\"\"\n",
    "        Processes a PyG Batch object representing multiple slices.\n",
    "        Args:\n",
    "            data (torch_geometric.data.Batch): A batch of slices, containing:\n",
    "                - data.x (Tensor): All points from all slices concatenated [N_total_points, 2].\n",
    "                - data.batch (Tensor): A tensor mapping each point to its original slice\n",
    "                                    in the batch [N_total_points].\n",
    "        Returns:\n",
    "            Tensor: A tensor of shape [num_slices_in_batch, emb_dim].\n",
    "        \"\"\"\n",
    "        # 1. Dynamically build the k-NN graph for the current set of points.\n",
    "        #    `knn_graph` is batch-aware and will not connect points from different slices.\n",
    "        edge_index = knn_graph(data.x, k=self.k, batch=data.batch)\n",
    "\n",
    "        # 2. Apply the EdgeConv layer to learn features for each point.\n",
    "        point_features = self.edge_conv(data.x, edge_index)\n",
    "\n",
    "        # 3. Use global max pooling to get ONE fixed-size vector per slice.\n",
    "        #    `global_max_pool` is also batch-aware.\n",
    "        slice_embedding = global_max_pool(point_features, data.batch)\n",
    "\n",
    "        return slice_embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0225096",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ################################\n",
    "# Attention Pooling Transformer Encoder\n",
    "# ################################\n",
    "# --- Your helper function (define this once outside the class) ---\n",
    "def generate_sinusoidal_position_embeddings(max_seq_len, embedding_dim):\n",
    "    pe = torch.zeros(max_seq_len, embedding_dim)\n",
    "    position = torch.arange(0, max_seq_len, dtype=torch.float).unsqueeze(1)\n",
    "    div_term = torch.exp(torch.arange(0, embedding_dim, 2).float() * (-math.log(10000.0) / embedding_dim))\n",
    "    pe[:, 0::2] = torch.sin(position * div_term)\n",
    "    pe[:, 1::2] = torch.cos(position * div_term)\n",
    "    return pe.unsqueeze(0) # Add batch dimension for (1, S, D)\n",
    "\n",
    "# --- Your TransformerSliceEncoder class ---\n",
    "class TransformerSliceEncoder(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        input_dim: int = 256, \n",
    "        hidden_dim: int = 256,\n",
    "        num_layers: int = 2,\n",
    "        nhead: int = 1,\n",
    "        dropout: float = 0.1,\n",
    "        max_seq_len: int = 80, # Fixed at 80\n",
    "    ):\n",
    "        super().__init__()\n",
    "        # KEY CHANGE 1: Use the pre-calculated sinusoidal embeddings\n",
    "        # We register it as a buffer so it's moved to GPU with the model,\n",
    "        # but NOT optimized by the optimizer (fixed).\n",
    "        self.register_buffer(\n",
    "            'pos_encoder',\n",
    "            generate_sinusoidal_position_embeddings(max_seq_len, input_dim)\n",
    "        )\n",
    "\n",
    "        encoder_layer = nn.TransformerEncoderLayer(\n",
    "            d_model=input_dim,\n",
    "            nhead=nhead,\n",
    "            dim_feedforward=hidden_dim * 2,\n",
    "            dropout=dropout,\n",
    "            batch_first=True,\n",
    "            activation=\"relu\"\n",
    "        )\n",
    "        self.transformer = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)\n",
    "\n",
    "        self.attn_pool = nn.Linear(input_dim, 1)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x: torch.Tensor, src_key_padding_mask: torch.Tensor = None):\n",
    "        \"\"\"\n",
    "        x: (B, S, D)\n",
    "        src_key_padding_mask: (B, S) mask with True = pad, False = valid\n",
    "        \"\"\"\n",
    "        B, S, D = x.shape\n",
    "        # KEY CHANGE 2: No change here, the addition logic remains the same.\n",
    "        # Now, self.pos_encoder contains fixed, meaningful position info.\n",
    "        x = x + self.pos_encoder[:, :S, :]\n",
    "\n",
    "        out = self.transformer(x, src_key_padding_mask=src_key_padding_mask)\n",
    "\n",
    "        # Attention pooling\n",
    "        scores = self.attn_pool(out).squeeze(-1)  # (B, S)\n",
    "        \n",
    "        if src_key_padding_mask is not None:\n",
    "            scores = scores.masked_fill(src_key_padding_mask, -1e9)\n",
    "\n",
    "        attn_weights = torch.softmax(scores, dim=-1)  # (B, S)\n",
    "        pooled = torch.sum(attn_weights.unsqueeze(-1) * out, dim=1)  # (B, D)\n",
    "\n",
    "        return self.dropout(pooled)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "824a7172",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ################################\n",
    "# Regression Model for Cd\n",
    "# ################################\n",
    "\n",
    "class CdRegressor(nn.Module):\n",
    "    def __init__(self, input_dim=256):  \n",
    "        \"\"\"\n",
    "        A simple regression model to predict the average drag coefficient (Cd) from the output of the TransformerSliceEncoder.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(input_dim, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 128),\n",
    "            nn.ReLU(), \n",
    "            nn.Linear(128, 1)  # Output layer for regression\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        x: (B, input_dim)\n",
    "        returns: (B,)\n",
    "        \"\"\"\n",
    "        return self.net(x).squeeze(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "020da62f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PREDICTOR NET FOR EXPERIMENTING EDGE CONV\n",
    "class CdPredictorNet(nn.Module):\n",
    "    def __init__(self, slice_encoder, transformer_encoder, regressor):\n",
    "        super().__init__()\n",
    "        self.slice_encoder = slice_encoder\n",
    "        self.transformer_encoder = transformer_encoder\n",
    "        self.regressor = regressor\n",
    "\n",
    "    def forward(self, car_slice_batches):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            car_slice_batches (list of torch_geometric.data.Batch):\n",
    "                A list of length 80. Each element is a PyG Batch object\n",
    "                representing all slices at that index from the main training batch.\n",
    "        \"\"\"\n",
    "        device = next(self.parameters()).device\n",
    "        slice_embeddings = []\n",
    "\n",
    "        for slice_batch in car_slice_batches:\n",
    "            slice_batch = slice_batch.to(device)\n",
    "            embedding = self.slice_encoder(slice_batch)\n",
    "            slice_embeddings.append(embedding)\n",
    "\n",
    "        transformer_input = torch.stack(slice_embeddings, dim=0)\n",
    "        transformer_input = transformer_input.transpose(0, 1)\n",
    "\n",
    "        car_emb = self.transformer_encoder(transformer_input)\n",
    "\n",
    "        return self.regressor(car_emb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d6fcc65",
   "metadata": {},
   "source": [
    "# Dataset loader and Model Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "385df74a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # -----------------------------\n",
    "# # 6. Dataset Loader\n",
    "# # -----------------------------\n",
    "# class CarSlicesDataset(torch.utils.data.Dataset):\n",
    "#     def __init__(self, ids_txt, npz_dir, csv_path, max_cars=None, scaler = None):\n",
    "#         \"\"\"\n",
    "#         Args:\n",
    "#             ids_txt (str): Path to the text file containing car IDs.\n",
    "#             npz_dir (str): Directory containing the .npz files.\n",
    "#             csv_path (str): Path to the CSV file with Cd values.\n",
    "#             max_cars (int, optional): Limit the number of cars to load. Defaults to None.\n",
    "#             scaler (object, optional): Scaler object for normalizing Cd values. Defaults to None.\n",
    "#         \"\"\"\n",
    "#         self.car_ids = [line.strip() for line in open(ids_txt)]\n",
    "#         if max_cars:\n",
    "#             self.car_ids = self.car_ids[:max_cars]\n",
    "#         self.npz_dir = npz_dir\n",
    "#         self.cd_map = pd.read_csv(csv_path).set_index(\"Design\")[\"Average Cd\"].to_dict()\n",
    "#         self.scaler = scaler if scaler else None\n",
    "\n",
    "#     def __len__(self):\n",
    "#         return len(self.car_ids)\n",
    "\n",
    "#     def __getitem__(self, idx):\n",
    "        \n",
    "#         car_id = self.car_ids[idx]\n",
    "#         data = np.load(os.path.join(self.npz_dir, f\"{car_id}_axis-x.npz\"))\n",
    "\n",
    "#         # Keep in NumPy for now (better for pin_memory and batch collation)\n",
    "#         slices = data[\"slices\"].astype(np.float32)         # (80, 6500, 2)\n",
    "#         point_mask = data[\"point_mask\"].astype(np.float32) # (80, 6500)\n",
    "#         slice_mask = data[\"slice_mask\"].astype(np.float32) # (80,)\n",
    "#         cd_value = np.float32(self.cd_map[car_id])\n",
    "\n",
    "#         if self.scaler:\n",
    "#             cd_value = self.scaler.transform([[cd_value]])[0, 0]\n",
    "\n",
    "#         return slices, point_mask, slice_mask, cd_value\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f192830",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ################################\n",
    "# Dataset with Optional Size Control\n",
    "# ################################\n",
    "class CarSlicesDataset_PyG(torch.utils.data.Dataset):\n",
    "    def __init__(self, ids_txt, raw_npy_dir, csv_path, scaler=None, max_size=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            ids_txt (str): Path to the text file containing car IDs.\n",
    "            raw_npy_dir (str): Directory containing the RAW .npy files (object arrays).\n",
    "            csv_path (str): Path to the CSV file with Cd values.\n",
    "            scaler (object, optional): Scaler for normalizing Cd values.\n",
    "            max_size (int, optional): If specified, limits number of cars loaded.\n",
    "        \"\"\"\n",
    "        all_ids = [line.strip() for line in open(ids_txt)]\n",
    "        if max_size is not None:\n",
    "            self.car_ids = all_ids[:max_size]\n",
    "        else:\n",
    "            self.car_ids = all_ids\n",
    "\n",
    "        self.raw_npy_dir = raw_npy_dir\n",
    "        self.cd_map = pd.read_csv(csv_path).set_index(\"Design\")[\"Average Cd\"].to_dict()\n",
    "        self.scaler = scaler\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.car_ids)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        car_id = self.car_ids[idx]\n",
    "        raw_slices = np.load(os.path.join(self.raw_npy_dir, f\"{car_id}_axis-x.npy\"), allow_pickle=True)\n",
    "        cd_value = np.float32(self.cd_map[car_id])\n",
    "\n",
    "        slice_data_list = [\n",
    "            Data(x=torch.from_numpy(s.astype(np.float32))) for s in raw_slices\n",
    "        ]\n",
    "\n",
    "        if self.scaler:\n",
    "            cd_value = self.scaler.transform([[cd_value]])[0, 0]\n",
    "\n",
    "        return slice_data_list, cd_value\n",
    "\n",
    "\n",
    "# ################################\n",
    "# Unchanged Collate Function\n",
    "# ################################\n",
    "def collate_fn_pyg(batch):\n",
    "    car_data_list, cd_list = zip(*batch)\n",
    "    slices_by_index = zip(*car_data_list)\n",
    "    batched_slices = [Batch.from_data_list(slice_list) for slice_list in slices_by_index]\n",
    "    cd_values = torch.tensor(cd_list, dtype=torch.float32)\n",
    "    return batched_slices, cd_values\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c75f8f7",
   "metadata": {},
   "source": [
    "# Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eddcebf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Custom RMSE metric\n",
    "class RMSE(Metric):\n",
    "    def reset(self):\n",
    "        self._sum_squared_error = 0.0\n",
    "        self._num_examples = 0\n",
    "\n",
    "    def update(self, output):\n",
    "        y_pred, y = output\n",
    "        errors = (y_pred - y) ** 2\n",
    "        self._sum_squared_error += torch.sum(errors).item()\n",
    "        self._num_examples += y.shape[0]\n",
    "\n",
    "    def compute(self):\n",
    "        return (self._sum_squared_error / self._num_examples) ** 0.5\n",
    "\n",
    "# Custom R² metric\n",
    "class R2Score(Metric):\n",
    "    def reset(self):\n",
    "        self._y_true = []\n",
    "        self._y_pred = []\n",
    "\n",
    "    def update(self, output):\n",
    "        y_pred, y = output\n",
    "        self._y_pred.extend(y_pred.detach().cpu().numpy().flatten())\n",
    "        self._y_true.extend(y.detach().cpu().numpy().flatten())\n",
    "\n",
    "    def compute(self):\n",
    "        return r2_score(self._y_true, self._y_pred)\n",
    "\n",
    "\n",
    "# Create training engine ---\n",
    "def create_trainer(model, optimizer, loss_fn, device, accumulation_steps):\n",
    "    scaler = GradScaler()  # add the scaler\n",
    "\n",
    "    def _update(engine, batch):\n",
    "        model.train()\n",
    "        car_slice_batches, cd_gt = batch\n",
    "        cd_gt = cd_gt.to(device)\n",
    "\n",
    "        if (engine.state.iteration - 1) % accumulation_steps == 0:\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "        with autocast():\n",
    "            pred = model(car_slice_batches)\n",
    "            loss = loss_fn(pred, cd_gt.float()) / accumulation_steps\n",
    "\n",
    "        # Use scaler for backward\n",
    "        scaler.scale(loss).backward()\n",
    "\n",
    "        if (engine.state.iteration % accumulation_steps) == 0:\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "\n",
    "        return pred, cd_gt\n",
    "\n",
    "    return Engine(_update)\n",
    "\n",
    "# --- MODIFIED: Create evaluation engine ---\n",
    "def create_evaluator(model, loss_fn, device):\n",
    "    def _inference(engine, batch):\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            # NEW: Unpack the simplified batch format\n",
    "            car_slice_batches, cd_gt = batch\n",
    "            cd_gt = cd_gt.to(device) # Move only the GT tensor to the device here\n",
    "            with autocast():\n",
    "                # NEW: Pass only the list of batches to the model\n",
    "                pred = model(car_slice_batches)\n",
    "        return pred, cd_gt\n",
    "\n",
    "    return Engine(_inference)\n",
    "\n",
    "# Attach metrics to an engine\n",
    "def attach_metrics(engine, loss_fn):\n",
    "    Loss(loss_fn).attach(engine, \"loss\")\n",
    "    RMSE().attach(engine, \"rmse\")\n",
    "    R2Score().attach(engine, \"r2\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6449f0c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "def train_model(\n",
    "    resume: bool = True,\n",
    "    delete_previous_model_dir: bool = False,\n",
    "    num_epochs: int = 50,\n",
    "    batch_size: int = 1,\n",
    "    learning_rate: float = 1e-4,\n",
    "    accumulation_steps: int = 32,\n",
    "    early_stopping_patience: int = 5,\n",
    "    model_dir: str = \"./model_dir\",\n",
    "\n",
    "    # Dataset configuration\n",
    "    training_set_size: int = None,\n",
    "    validation_set_size: int = None,\n",
    "    train_ids_txt: str = \"../dataset/raw/subset_dir/train_design_ids.txt\",\n",
    "    val_ids_txt: str = \"../dataset/raw/subset_dir/val_design_ids.txt\",\n",
    "    raw_npy_dir: str = \"../dataset/processed/slices\",\n",
    "    csv_path: str = \"../dataset/raw/DrivAerNetPlusPlus_Drag_8k_cleaned.csv\",\n",
    "    scaler=None,\n",
    "\n",
    "    # # Model hyperparameters (Hyperparameter for EdgeConv) ---\n",
    "    k_neighbors: int = 25,\n",
    "    slice_embedding_dim: int = 256,\n",
    "    transformer_hidden_dim: int = 256,\n",
    "    transformer_num_layers: int = 2,\n",
    "    transformer_nhead: int = 1,\n",
    "    cd_regressor_input_dim: int = 256,\n",
    "):\n",
    "    checkpoints_dir = os.path.join(model_dir, \"checkpoints\")\n",
    "    results_dir = os.path.join(model_dir, \"results\")\n",
    "    os.makedirs(checkpoints_dir, exist_ok=True)\n",
    "    os.makedirs(results_dir, exist_ok=True)\n",
    "\n",
    "    # 1) Optional cleanup\n",
    "    if delete_previous_model_dir and not resume:\n",
    "        if os.path.isdir(model_dir) and os.listdir(model_dir):\n",
    "            confirm = input(f\"[WARN] Contents found in '{model_dir}'. Delete all contents? (yes/no): \").strip().lower()\n",
    "            if confirm == \"yes\":\n",
    "                # Delete all contents inside model_dir\n",
    "                for entry in os.scandir(model_dir):\n",
    "                    if entry.is_dir():\n",
    "                        shutil.rmtree(entry.path)\n",
    "                    else:\n",
    "                        os.remove(entry.path)\n",
    "                print(f\"[INFO] All contents of '{model_dir}' have been deleted.\")\n",
    "            else:\n",
    "                print(\"[INFO] Cleanup aborted by user.\")\n",
    "        else:\n",
    "            print(f\"[INFO] Nothing to clean. '{model_dir}' is empty or does not exist.\")\n",
    "\n",
    "\n",
    "    # 2) Model setup\n",
    "    \n",
    "    # --- MODIFIED: Model setup ---\n",
    "    print(f\"[INFO] Setting up model with k={k_neighbors} for EdgeConv...\")\n",
    "    slice_encoder = EdgeConvSliceEncoder(input_dim=2, emb_dim=slice_embedding_dim, k=k_neighbors)\n",
    "    encoder = TransformerSliceEncoder(input_dim=slice_embedding_dim, hidden_dim=transformer_hidden_dim, num_layers=transformer_num_layers, nhead=transformer_nhead)\n",
    "    regressor = CdRegressor(input_dim=cd_regressor_input_dim)\n",
    "    model = CdPredictorNet(slice_encoder, encoder, regressor).to(device)\n",
    "\n",
    "\n",
    "    print(model)\n",
    "    print(f\"[INFO] Total trainable parameters: {sum(p.numel() for p in model.parameters() if p.requires_grad):,}\")\n",
    "\n",
    "    # 3) Training components\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)    \n",
    "    loss_fn = nn.SmoothL1Loss()\n",
    "    trainer = create_trainer(model, optimizer, loss_fn, device, accumulation_steps)\n",
    "    evaluator = create_evaluator(model, loss_fn, device)\n",
    "    attach_metrics(trainer, loss_fn)\n",
    "    attach_metrics(evaluator, loss_fn)\n",
    "\n",
    "    train_pbar = ProgressBar(persist=True, desc=\"Training\")\n",
    "    train_pbar.attach(trainer, metric_names=[\"loss\", \"rmse\", \"r2\"])\n",
    "    val_pbar = ProgressBar(persist=True, desc=\"Validation\")\n",
    "    val_pbar.attach(evaluator, metric_names=[\"loss\", \"rmse\", \"r2\"])\n",
    "\n",
    "    # 4) Data setup ---\n",
    "    print(f\"[INFO] Loading data from raw npy directory: {raw_npy_dir}\")\n",
    "    train_dataset = CarSlicesDataset_PyG(train_ids_txt, raw_npy_dir, csv_path, scaler, training_set_size)\n",
    "    val_dataset = CarSlicesDataset_PyG(val_ids_txt, raw_npy_dir, csv_path, scaler, validation_set_size)\n",
    "\n",
    "    train_loader = PyGDataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True,\n",
    "        collate_fn=collate_fn_pyg,\n",
    "    )\n",
    "    val_loader = PyGDataLoader(\n",
    "        val_dataset,\n",
    "        batch_size=batch_size * 2,\n",
    "        shuffle=False,\n",
    "        collate_fn=collate_fn_pyg,\n",
    "    )\n",
    "\n",
    "    # 5) Resume\n",
    "    start_epoch = 1\n",
    "    if resume:\n",
    "        ckpts = sorted(glob.glob(os.path.join(checkpoints_dir, \"epoch_*.pt\")))\n",
    "        if ckpts:\n",
    "            last_ckpt = ckpts[-1]\n",
    "            print(f\"[INFO] Resuming from checkpoint: {os.path.basename(last_ckpt)}\")\n",
    "            data = torch.load(last_ckpt, map_location=device)\n",
    "            model.load_state_dict(data[\"model\"])\n",
    "            optimizer.load_state_dict(data[\"optimizer\"])\n",
    "            start_epoch = data.get(\"epoch\", 1) + 1\n",
    "        else:\n",
    "            print(\"[INFO] No checkpoint found. Starting fresh.\")\n",
    "\n",
    "    # 6) TensorBoard\n",
    "    tb_writer = SummaryWriter(log_dir=os.path.join(checkpoints_dir, \"logs\"), purge_step=start_epoch - 1)\n",
    "\n",
    "    # 7) Best model saving\n",
    "    evaluator.add_event_handler(Events.COMPLETED, ModelCheckpoint(\n",
    "        dirname=checkpoints_dir,\n",
    "        filename_prefix=\"best_model\",\n",
    "        n_saved=1,\n",
    "        score_function=lambda eng: eng.state.metrics[\"r2\"],\n",
    "        score_name=\"r2\",\n",
    "        global_step_transform=lambda eng, _: eng.state.epoch + start_epoch - 1,\n",
    "        require_empty=False\n",
    "    ), {\"model\": model})\n",
    "\n",
    "    # 8) Early stopping\n",
    "    evaluator.add_event_handler(Events.COMPLETED, EarlyStopping(\n",
    "        patience=early_stopping_patience,\n",
    "        score_function=lambda eng: eng.state.metrics[\"r2\"],\n",
    "        trainer=trainer\n",
    "    ))\n",
    "\n",
    "    # 9) Load previous history if exists\n",
    "    history_path = os.path.join(results_dir, \"training_history.json\")\n",
    "    new_history = []\n",
    "    if os.path.exists(history_path):\n",
    "        with open(history_path, \"r\") as f:\n",
    "            new_history = json.load(f)\n",
    "    else:\n",
    "        # Create the directory if it doesn't exist\n",
    "        os.makedirs(os.path.dirname(history_path), exist_ok=True)\n",
    "\n",
    "    # 10) Validation handler\n",
    "    @trainer.on(Events.EPOCH_COMPLETED)\n",
    "    def validate(engine):\n",
    "        evaluator.run(val_loader)\n",
    "        epoch_num = engine.state.epoch + start_epoch - 1\n",
    "        train_metrics = engine.state.metrics\n",
    "        val_metrics = evaluator.state.metrics\n",
    "    \n",
    "    # 11) Record and log metrics and save history \n",
    "        record = {\n",
    "            \"epoch\": epoch_num,\n",
    "            \"Train_loss\": train_metrics[\"loss\"],\n",
    "            \"Train_rmse\": train_metrics[\"rmse\"],\n",
    "            \"Train_r2\": train_metrics[\"r2\"],\n",
    "            \"Val_loss\": val_metrics[\"loss\"],\n",
    "            \"Val_rmse\": val_metrics[\"rmse\"],\n",
    "            \"Val_r2\": val_metrics[\"r2\"],\n",
    "        }\n",
    "        new_history.append(record)\n",
    "\n",
    "        tb_writer.add_scalars(\"Loss\", {\n",
    "            \"Train\": train_metrics[\"loss\"],\n",
    "            \"Validation\": val_metrics[\"loss\"]\n",
    "        }, epoch_num)\n",
    "        tb_writer.add_scalars(\"RMSE\", {\n",
    "            \"Train\": train_metrics[\"rmse\"],\n",
    "            \"Validation\": val_metrics[\"rmse\"]\n",
    "        }, epoch_num)\n",
    "        tb_writer.add_scalars(\"R2\", {\n",
    "            \"Train\": train_metrics[\"r2\"],\n",
    "            \"Validation\": val_metrics[\"r2\"]\n",
    "        }, epoch_num)\n",
    "\n",
    "        print(f\"\\n[Epoch {epoch_num:03d}] ------------------------\")\n",
    "        for key, value in record.items():\n",
    "            if key != \"epoch\":\n",
    "                print(f\"{key:17}: {value:.6f}\" if isinstance(value, float) else f\"{key:17}: {value}\")\n",
    "\n",
    "        with open(history_path + \".bak\", \"w\") as f:\n",
    "            json.dump(new_history, f, indent=2)\n",
    "        with open(history_path, \"w\") as f:\n",
    "            json.dump(new_history, f, indent=2)\n",
    "\n",
    "        torch.save({\n",
    "            \"epoch\": epoch_num,\n",
    "            \"model\": model.state_dict(),\n",
    "            \"optimizer\": optimizer.state_dict()\n",
    "        }, os.path.join(checkpoints_dir, f\"epoch_{epoch_num:03d}_loss_{val_metrics['loss']:.8f}.pt\"))\n",
    "\n",
    "    # 11) Run training\n",
    "    try:\n",
    "        trainer.run(train_loader, max_epochs=num_epochs - start_epoch + 1)\n",
    "    except KeyboardInterrupt:\n",
    "        print(\"\\n⛔ Training interrupted by user.\")\n",
    "    finally:\n",
    "        tb_writer.close()\n",
    "        best_ckpt = sorted(glob.glob(os.path.join(checkpoints_dir, \"best_model_*.pt\")))\n",
    "        if best_ckpt:\n",
    "            print(f\"[INFO] Loading best model from: {os.path.basename(best_ckpt[-1])}\")\n",
    "            best_model_data = torch.load(best_ckpt[-1], map_location=device)\n",
    "            model.load_state_dict(best_model_data[\"model\"] if \"model\" in best_model_data else best_model_data)\n",
    "\n",
    "        with open(history_path, \"r\") as f:\n",
    "            final_history = json.load(f)\n",
    "        return model, final_history\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "956f8fb3",
   "metadata": {},
   "source": [
    "# Training Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8541b5f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directories\n",
    "model_dir = \"../model_outputs/DTM256_Model\"\n",
    "checkpoints_dir = os.path.join(model_dir, \"checkpoints\")\n",
    "results_dir = os.path.join(model_dir, \"results\")\n",
    "os.makedirs(checkpoints_dir, exist_ok=True)\n",
    "os.makedirs(results_dir, exist_ok=True)\n",
    "\n",
    "# History file paths\n",
    "json_history_path = os.path.join(results_dir, \"training_history.json\")\n",
    "\n",
    "# Call the training function\n",
    "model, _ = train_model(\n",
    "    # General training configuration\n",
    "    resume=False,\n",
    "    delete_previous_model_dir=True,\n",
    "    num_epochs=100,\n",
    "    batch_size=4,\n",
    "    learning_rate=1e-4,\n",
    "    accumulation_steps=1,\n",
    "    early_stopping_patience= 10,\n",
    "    model_dir = model_dir,\n",
    "\n",
    "    # Dataset configuration\n",
    "    training_set_size = 100,\n",
    "    validation_set_size = 20,\n",
    "    train_ids_txt=\"../dataset/raw/subset_dir/train_design_ids.txt\",\n",
    "    val_ids_txt=\"../dataset/raw/subset_dir/val_design_ids.txt\",\n",
    "    raw_npy_dir = \"../dataset/processed/slices\",\n",
    "    csv_path  = \"../dataset/raw/DrivAerNetPlusPlus_Drag_8k_cleaned.csv\",\n",
    "    scaler=scaler,\n",
    "\n",
    "    # --- MODIFIED: Model hyperparameters ---\n",
    "    k_neighbors=20, # The new hyperparameter for EdgeConv\n",
    "    slice_embedding_dim = 256,\n",
    "    transformer_hidden_dim = 256,\n",
    "    transformer_num_layers = 4,\n",
    "    transformer_nhead = 4,\n",
    "    cd_regressor_input_dim= 256,\n",
    ")\n",
    "\n",
    "# Load Json history and convert to DataFrame and print\n",
    "history_df = pd.read_json(json_history_path)\n",
    "print(history_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92070095",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
