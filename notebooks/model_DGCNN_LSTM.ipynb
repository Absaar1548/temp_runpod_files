{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "218ba7f2",
   "metadata": {},
   "source": [
    "# Importing Packages\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4fcd0faa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3.0+cu121\n",
      "12.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Windows\\Temp\\ipykernel_8212\\3371436108.py:45: DeprecationWarning: d:\\Temp_Work\\Run_Pod_Files\\.venv\\lib\\site-packages\\ignite\\contrib\\handlers\\tensorboard_logger.py has been moved to /ignite/handlers/tensorboard_logger.py and will be removed in version 0.6.0.\n",
      " Please refer to the documentation for more details.\n",
      "  from ignite.contrib.handlers.tensorboard_logger import TensorboardLogger\n"
     ]
    }
   ],
   "source": [
    "# -----------------------------\n",
    "# 1. Imports and Seed Setup\n",
    "# -----------------------------\n",
    "\n",
    "# Standard library\n",
    "import os\n",
    "import glob\n",
    "import math\n",
    "import re\n",
    "import shutil\n",
    "import time\n",
    "import json\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "\n",
    "# Third-party\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "import joblib\n",
    "\n",
    "# PyTorch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.backends.cudnn as cudnn\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "\n",
    "# PyTorch Geometric\n",
    "from torch_geometric.data import Data, Batch\n",
    "from torch_geometric.loader import DataLoader as PyGDataLoader\n",
    "from torch_geometric.nn import EdgeConv, knn_graph, global_max_pool\n",
    "\n",
    "\n",
    "# PyTorch Ignite\n",
    "from ignite.engine import Engine, Events\n",
    "from ignite.metrics import Loss\n",
    "from ignite.metrics.metric import Metric\n",
    "from ignite.handlers import ModelCheckpoint, EarlyStopping\n",
    "from ignite.contrib.handlers import ProgressBar\n",
    "from ignite.contrib.handlers.tensorboard_logger import TensorboardLogger\n",
    "\n",
    "# Warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Reproducibility\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "cudnn.deterministic = True\n",
    "cudnn.benchmark = False\n",
    "\n",
    "\n",
    "print(torch.__version__)     # e.g., 2.1.0\n",
    "print(torch.version.cuda) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8f71c1d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ PyG extensions loaded and working.\n"
     ]
    }
   ],
   "source": [
    "# -----------------------------\n",
    "# PyG Extension Sanity Check\n",
    "# -----------------------------\n",
    "try:\n",
    "    import torch_scatter\n",
    "    import torch_sparse\n",
    "    import torch_cluster\n",
    "    import torch_spline_conv\n",
    "    from torch_geometric.nn import knn_graph\n",
    "\n",
    "    # Create dummy inputs\n",
    "    x = torch.randn(32, 3).cuda()  # 32 3D points\n",
    "    batch = torch.zeros(32, dtype=torch.long).cuda()\n",
    "    edge_index = knn_graph(x, k=4, batch=batch)\n",
    "\n",
    "    print(\"✅ PyG extensions loaded and working.\")\n",
    "except ImportError as e:\n",
    "    print(\"❌ PyG Import Error:\", e)\n",
    "except Exception as e:\n",
    "    print(\"❌ PyG Runtime Error:\", e)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15e54c9f",
   "metadata": {},
   "source": [
    "# EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "951a8a0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Average Cd",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "bfded8cc-d6ec-4fb9-a50b-04cea709ebd3",
       "rows": [
        [
         "count",
         "7713.0"
        ],
        [
         "mean",
         "0.2844122596453961"
        ],
        [
         "std",
         "0.037232202870494696"
        ],
        [
         "min",
         "0.201138367156146"
        ],
        [
         "25%",
         "0.255859366461794"
        ],
        [
         "50%",
         "0.282986553124688"
        ],
        [
         "75%",
         "0.311521421763092"
        ],
        [
         "max",
         "0.383329962159601"
        ]
       ],
       "shape": {
        "columns": 1,
        "rows": 8
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Average Cd</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>7713.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.284412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.037232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.201138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.255859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.282987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.311521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.383330</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Average Cd\n",
       "count  7713.000000\n",
       "mean      0.284412\n",
       "std       0.037232\n",
       "min       0.201138\n",
       "25%       0.255859\n",
       "50%       0.282987\n",
       "75%       0.311521\n",
       "max       0.383330"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_path = Path(\"..\") / \"dataset\" / \"raw\" / \"DrivAerNetPlusPlus_Drag_8k_cleaned.csv\"\n",
    "df = pd.read_csv(file_path)\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c14b960c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA Available: True\n",
      "Using device: cuda\n",
      "GPU Name: NVIDIA GeForce RTX 4060 Laptop GPU\n",
      "Memory Allocated: 0.0029296875 MB\n",
      "Memory Cached: 2.0 MB\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Check if CUDA is available\n",
    "print(\"CUDA Available:\", torch.cuda.is_available())\n",
    "\n",
    "# Get current device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "# Print GPU name\n",
    "if torch.cuda.is_available():\n",
    "    print(\"GPU Name:\", torch.cuda.get_device_name(0))\n",
    "    print(\"Memory Allocated:\", torch.cuda.memory_allocated(0) / 1024**2, \"MB\")\n",
    "    print(\"Memory Cached:\", torch.cuda.memory_reserved(0) / 1024**2, \"MB\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f7fe6b21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: xlabel='Average Cd', ylabel='Count'>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the pdf graph for Average Drag Coefficient (Cd)\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.histplot(df['Average Cd'], bins=30, kde=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41516c9c",
   "metadata": {},
   "source": [
    "# Pepraring Scaler Function and Global variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e1a83241",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scaler mean: 0.284506, std: 0.037448\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['..\\\\dataset\\\\scaler\\\\cd_scaler.pkl']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# -----------------------------\n",
    "# 1.2.1. Prepaing Scaler\n",
    "# -----------------------------\n",
    "\n",
    "# Base path\n",
    "base_path = Path(\"..\") / \"dataset\"\n",
    "\n",
    "# Subset to only training car IDs\n",
    "train_ids_path = base_path / \"raw\" / \"subset_dir\" / \"train_design_ids.txt\"\n",
    "with open(train_ids_path) as f:\n",
    "    train_ids = [line.strip() for line in f]\n",
    "\n",
    "df_train = df[df[\"Design\"].isin(train_ids)]\n",
    "\n",
    "cd_scaler = StandardScaler()\n",
    "cd_scaler.fit(df_train[[\"Average Cd\"]])\n",
    "\n",
    "print(f\"Scaler mean: {cd_scaler.mean_[0]:.6f}, std: {cd_scaler.scale_[0]:.6f}\")\n",
    "\n",
    "# Save cd_scaler to disk\n",
    "scaler_dir = base_path / \"scaler\"\n",
    "scaler_dir.mkdir(parents=True, exist_ok=True)\n",
    "joblib.dump(cd_scaler, scaler_dir / \"cd_scaler.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b8f16e0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Found existing point scaler. Loading from ..\\dataset\\scaler\\point_scaler.pkl\n",
      "\n",
      "Point Scaler Ready:\n",
      "  Mean: [-0.00664036  0.52892731]\n",
      "  Std:  [0.65939748 0.38759915]\n"
     ]
    }
   ],
   "source": [
    "# -----------------------------\n",
    "# 1.2.2. Prepaing Point_Scaler\n",
    "# -----------------------------\n",
    "from pathlib import Path\n",
    "import joblib\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# Define paths\n",
    "scaler_dir = Path(\"../dataset/scaler\")\n",
    "point_scaler_path = scaler_dir / \"point_scaler.pkl\"\n",
    "\n",
    "# Check if the scaler file already exists\n",
    "if point_scaler_path.exists():\n",
    "    print(f\"[INFO] Found existing point scaler. Loading from {point_scaler_path}\")\n",
    "    point_scaler = joblib.load(point_scaler_path)\n",
    "else:\n",
    "    print(\"[INFO] Point scaler not found. Generating a new one...\")\n",
    "    \n",
    "    # --- Original generation script ---\n",
    "    ids_txt = \"../dataset/raw/subset_dir/train_design_ids.txt\"\n",
    "    raw_npy_dir = \"../dataset/processed/slices\"\n",
    "    train_ids = [line.strip() for line in open(ids_txt)]\n",
    "\n",
    "    print(\"Calculating stats for input point coordinates from the training set...\")\n",
    "    point_sample = []\n",
    "    # Iterate through all training IDs to get a representative statistic\n",
    "    for car_id in tqdm(train_ids, desc=\"Scanning raw slices\"): \n",
    "        slices_path = os.path.join(raw_npy_dir, f\"{car_id}_axis-x.npy\")\n",
    "        if os.path.exists(slices_path):\n",
    "            slices = np.load(slices_path, allow_pickle=True)\n",
    "            for s in slices:\n",
    "                # Ensure the slice is not empty\n",
    "                if s.shape[0] > 0:\n",
    "                    point_sample.append(s)\n",
    "\n",
    "    # Vertically stack all points from all slices into one large array\n",
    "    all_points = np.vstack(point_sample)\n",
    "\n",
    "    # Fit a scaler on the (x, y) coordinates of the points\n",
    "    point_scaler = StandardScaler()\n",
    "    point_scaler.fit(all_points)\n",
    "\n",
    "    print(\"[INFO] New scaler generated. Saving to disk...\")\n",
    "    # Ensure the directory exists before saving\n",
    "    scaler_dir.mkdir(parents=True, exist_ok=True)\n",
    "    joblib.dump(point_scaler, point_scaler_path)\n",
    "    print(f\"[INFO] Scaler saved successfully to {point_scaler_path}\")\n",
    "\n",
    "# This will print the stats for either the loaded or newly generated scaler\n",
    "print(f\"\\nPoint Scaler Ready:\")\n",
    "print(f\"  Mean: {point_scaler.mean_}\")\n",
    "print(f\"  Std:  {point_scaler.scale_}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70da915d",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6f350841",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ###################################\n",
    "# Minimal EdgeConv Slice Encoder (Replaces PointNet2D)\n",
    "# ###################################\n",
    "class EdgeConvSliceEncoder(nn.Module):\n",
    "    \"\"\"\n",
    "    Encodes a batch of 2D slices, each with a variable number of points,\n",
    "    into a fixed-size embedding vector for each slice.\n",
    "    This module is designed to work with PyTorch Geometric's Batch object.\n",
    "    \"\"\"\n",
    "    def __init__(self, input_dim=2, emb_dim=256, k=20):\n",
    "        super().__init__()\n",
    "        self.k = k\n",
    "\n",
    "        # Define the MLP that will be used inside EdgeConv\n",
    "        # It processes concatenated features of a point and its neighbors\n",
    "        mlp = nn.Sequential(\n",
    "            nn.Linear(2 * input_dim, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, emb_dim) # Output the final embedding dimension\n",
    "        )\n",
    "\n",
    "        # The EdgeConv layer itself\n",
    "        self.edge_conv = EdgeConv(nn=mlp, aggr='max')\n",
    "\n",
    "    def forward(self, data):\n",
    "        \"\"\"\n",
    "        Processes a PyG Batch object representing multiple slices.\n",
    "        Args:\n",
    "            data (torch_geometric.data.Batch): A batch of slices, containing:\n",
    "                - data.x (Tensor): All points from all slices concatenated [N_total_points, 2].\n",
    "                - data.batch (Tensor): A tensor mapping each point to its original slice\n",
    "                                    in the batch [N_total_points].\n",
    "        Returns:\n",
    "            Tensor: A tensor of shape [num_slices_in_batch, emb_dim].\n",
    "        \"\"\"\n",
    "        # 1. Dynamically build the k-NN graph for the current set of points.\n",
    "        #    `knn_graph` is batch-aware and will not connect points from different slices.\n",
    "        edge_index = knn_graph(data.x, k=self.k, batch=data.batch)\n",
    "\n",
    "        # 2. Apply the EdgeConv layer to learn features for each point.\n",
    "        point_features = self.edge_conv(data.x, edge_index)\n",
    "\n",
    "        # 3. Use global max pooling to get ONE fixed-size vector per slice.\n",
    "        #    `global_max_pool` is also batch-aware.\n",
    "        slice_embedding = global_max_pool(point_features, data.batch)\n",
    "\n",
    "        return slice_embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c0225096",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ################################\n",
    "# Attention Pooling Transformer Encoder\n",
    "# ################################\n",
    "# --- Your helper function (define this once outside the class) ---\n",
    "def generate_sinusoidal_position_embeddings(max_seq_len, embedding_dim):\n",
    "    pe = torch.zeros(max_seq_len, embedding_dim)\n",
    "    position = torch.arange(0, max_seq_len, dtype=torch.float).unsqueeze(1)\n",
    "    div_term = torch.exp(torch.arange(0, embedding_dim, 2).float() * (-math.log(10000.0) / embedding_dim))\n",
    "    pe[:, 0::2] = torch.sin(position * div_term)\n",
    "    pe[:, 1::2] = torch.cos(position * div_term)\n",
    "    return pe.unsqueeze(0) # Add batch dimension for (1, S, D)\n",
    "\n",
    "# --- Your TransformerSliceEncoder class ---\n",
    "class TransformerSliceEncoder(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        input_dim: int = 256, \n",
    "        hidden_dim: int = 256,\n",
    "        num_layers: int = 2,\n",
    "        nhead: int = 1,\n",
    "        dropout: float = 0.1,\n",
    "        max_seq_len: int = 80, # Fixed at 80\n",
    "    ):\n",
    "        super().__init__()\n",
    "        # KEY CHANGE 1: Use the pre-calculated sinusoidal embeddings\n",
    "        # We register it as a buffer so it's moved to GPU with the model,\n",
    "        # but NOT optimized by the optimizer (fixed).\n",
    "        self.register_buffer(\n",
    "            'pos_encoder',\n",
    "            generate_sinusoidal_position_embeddings(max_seq_len, input_dim)\n",
    "        )\n",
    "\n",
    "        encoder_layer = nn.TransformerEncoderLayer(\n",
    "            d_model=input_dim,\n",
    "            nhead=nhead,\n",
    "            dim_feedforward=hidden_dim * 2,\n",
    "            dropout=dropout,\n",
    "            batch_first=True,\n",
    "            activation=\"relu\"\n",
    "        )\n",
    "        self.transformer = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)\n",
    "\n",
    "        self.attn_pool = nn.Linear(input_dim, 1)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x: torch.Tensor, src_key_padding_mask: torch.Tensor = None):\n",
    "        \"\"\"\n",
    "        x: (B, S, D)\n",
    "        src_key_padding_mask: (B, S) mask with True = pad, False = valid\n",
    "        \"\"\"\n",
    "        B, S, D = x.shape\n",
    "        # KEY CHANGE 2: No change here, the addition logic remains the same.\n",
    "        # Now, self.pos_encoder contains fixed, meaningful position info.\n",
    "        x = x + self.pos_encoder[:, :S, :]\n",
    "\n",
    "        out = self.transformer(x, src_key_padding_mask=src_key_padding_mask)\n",
    "\n",
    "        # Attention pooling\n",
    "        scores = self.attn_pool(out).squeeze(-1)  # (B, S)\n",
    "        \n",
    "        if src_key_padding_mask is not None:\n",
    "            scores = scores.masked_fill(src_key_padding_mask, -1e9)\n",
    "\n",
    "        attn_weights = torch.softmax(scores, dim=-1)  # (B, S)\n",
    "        pooled = torch.sum(attn_weights.unsqueeze(-1) * out, dim=1)  # (B, D)\n",
    "\n",
    "        return self.dropout(pooled)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "824a7172",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ################################\n",
    "# Regression Model for Cd\n",
    "# ################################\n",
    "\n",
    "class CdRegressor(nn.Module):\n",
    "    def __init__(self, input_dim=256):  \n",
    "        \"\"\"\n",
    "        A simple regression model to predict the average drag coefficient (Cd) from the output of the TransformerSliceEncoder.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(input_dim, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 128),\n",
    "            nn.ReLU(), \n",
    "            nn.Linear(128, 1)  # Output layer for regression\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        x: (B, input_dim)\n",
    "        returns: (B,)\n",
    "        \"\"\"\n",
    "        return self.net(x).squeeze(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "020da62f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PREDICTOR NET FOR EXPERIMENTING EDGE CONV\n",
    "class CdPredictorNet(nn.Module):\n",
    "    def __init__(self, slice_encoder, transformer_encoder, regressor):\n",
    "        super().__init__()\n",
    "        self.slice_encoder = slice_encoder\n",
    "        self.transformer_encoder = transformer_encoder\n",
    "        self.regressor = regressor\n",
    "\n",
    "    def forward(self, car_slice_batches):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            car_slice_batches (list of torch_geometric.data.Batch):\n",
    "                A list of length 80. Each element is a PyG Batch object\n",
    "                representing all slices at that index from the main training batch.\n",
    "        \"\"\"\n",
    "        device = next(self.parameters()).device\n",
    "        slice_embeddings = []\n",
    "\n",
    "        for slice_batch in car_slice_batches:\n",
    "            slice_batch = slice_batch.to(device)\n",
    "            embedding = self.slice_encoder(slice_batch)\n",
    "            slice_embeddings.append(embedding)\n",
    "\n",
    "        transformer_input = torch.stack(slice_embeddings, dim=0)\n",
    "        transformer_input = transformer_input.transpose(0, 1)\n",
    "\n",
    "        car_emb = self.transformer_encoder(transformer_input)\n",
    "\n",
    "        return self.regressor(car_emb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d6fcc65",
   "metadata": {},
   "source": [
    "# Dataset loader and Model Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6f192830",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ################################\n",
    "# Dataset with Optional Size Control\n",
    "# ################################\n",
    "# In your CarSlicesDataset_PyG class\n",
    "class CarSlicesDataset_PyG(torch.utils.data.Dataset):\n",
    "    def __init__(self, ids_txt, raw_npy_dir, csv_path, cd_scaler=None, point_scaler=None, max_size=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            ids_txt (str): Path to the text file containing car IDs.\n",
    "            raw_npy_dir (str): Directory containing the RAW .npy files (object arrays).\n",
    "            csv_path (str): Path to the CSV file with Cd values.\n",
    "            scaler (object, optional): Scaler for normalizing Cd values.\n",
    "            max_size (int, optional): If specified, limits number of cars loaded.\n",
    "        \"\"\"\n",
    "        all_ids = [line.strip() for line in open(ids_txt)]\n",
    "        if max_size is not None:\n",
    "            self.car_ids = all_ids[:max_size]\n",
    "        else:\n",
    "            self.car_ids = all_ids\n",
    "\n",
    "        self.raw_npy_dir = raw_npy_dir\n",
    "        self.cd_map = pd.read_csv(csv_path).set_index(\"Design\")[\"Average Cd\"].to_dict()\n",
    "        self.cd_scaler = cd_scaler\n",
    "        self.point_scaler = point_scaler # Add this\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.car_ids)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        car_id = self.car_ids[idx]\n",
    "        raw_slices = np.load(os.path.join(self.raw_npy_dir, f\"{car_id}_axis-x.npy\"), allow_pickle=True)\n",
    "        cd_value = np.float32(self.cd_map[car_id])\n",
    "\n",
    "        # Apply point scaler if available\n",
    "        if self.point_scaler:\n",
    "            processed_slices = [self.point_scaler.transform(s) for s in raw_slices if s.shape[0] > 0]\n",
    "        else:\n",
    "            processed_slices = [s for s in raw_slices if s.shape[0] > 0]\n",
    "\n",
    "        slice_data_list = [\n",
    "            Data(x=torch.from_numpy(s.astype(np.float32))) for s in processed_slices\n",
    "        ]\n",
    "\n",
    "        if self.cd_scaler:\n",
    "            cd_value = self.cd_scaler.transform([[cd_value]])[0, 0]\n",
    "\n",
    "        return slice_data_list, cd_value\n",
    "\n",
    "# ################################\n",
    "# Unchanged Collate Function\n",
    "# ################################\n",
    "def collate_fn_pyg(batch):\n",
    "    car_data_list, cd_list = zip(*batch)\n",
    "    slices_by_index = zip(*car_data_list)\n",
    "    batched_slices = [Batch.from_data_list(slice_list) for slice_list in slices_by_index]\n",
    "    cd_values = torch.tensor(cd_list, dtype=torch.float32)\n",
    "    return batched_slices, cd_values\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c75f8f7",
   "metadata": {},
   "source": [
    "# Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "eddcebf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Custom RMSE metric\n",
    "class RMSE(Metric):\n",
    "    def reset(self):\n",
    "        self._sum_squared_error = 0.0\n",
    "        self._num_examples = 0\n",
    "\n",
    "    def update(self, output):\n",
    "        y_pred, y = output\n",
    "        errors = (y_pred - y) ** 2\n",
    "        self._sum_squared_error += torch.sum(errors).item()\n",
    "        self._num_examples += y.shape[0]\n",
    "\n",
    "    def compute(self):\n",
    "        return (self._sum_squared_error / self._num_examples) ** 0.5\n",
    "\n",
    "# Custom R² metric\n",
    "class R2Score(Metric):\n",
    "    def reset(self):\n",
    "        self._y_true = []\n",
    "        self._y_pred = []\n",
    "\n",
    "    def update(self, output):\n",
    "        y_pred, y = output\n",
    "        self._y_pred.extend(y_pred.detach().cpu().numpy().flatten())\n",
    "        self._y_true.extend(y.detach().cpu().numpy().flatten())\n",
    "\n",
    "    def compute(self):\n",
    "        return r2_score(self._y_true, self._y_pred)\n",
    "\n",
    "\n",
    "# Create training engine ---\n",
    "def create_trainer(model, optimizer, loss_fn, device, accumulation_steps):\n",
    "    scaler = GradScaler()  # add the scaler\n",
    "\n",
    "    def _update(engine, batch):\n",
    "        model.train()\n",
    "        car_slice_batches, cd_gt = batch\n",
    "        cd_gt = cd_gt.to(device)\n",
    "\n",
    "        if (engine.state.iteration - 1) % accumulation_steps == 0:\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "        with autocast():\n",
    "            pred = model(car_slice_batches)\n",
    "            loss = loss_fn(pred, cd_gt.float()) / accumulation_steps\n",
    "\n",
    "        # Use scaler for backward\n",
    "        scaler.scale(loss).backward()\n",
    "\n",
    "        if (engine.state.iteration % accumulation_steps) == 0:\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "\n",
    "        return pred, cd_gt\n",
    "\n",
    "    return Engine(_update)\n",
    "\n",
    "# --- MODIFIED: Create evaluation engine ---\n",
    "def create_evaluator(model, loss_fn, device):\n",
    "    def _inference(engine, batch):\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            # NEW: Unpack the simplified batch format\n",
    "            car_slice_batches, cd_gt = batch\n",
    "            cd_gt = cd_gt.to(device) # Move only the GT tensor to the device here\n",
    "            with autocast():\n",
    "                # NEW: Pass only the list of batches to the model\n",
    "                pred = model(car_slice_batches)\n",
    "        return pred, cd_gt\n",
    "\n",
    "    return Engine(_inference)\n",
    "\n",
    "# Attach metrics to an engine\n",
    "def attach_metrics(engine, loss_fn):\n",
    "    Loss(loss_fn).attach(engine, \"loss\")\n",
    "    RMSE().attach(engine, \"rmse\")\n",
    "    R2Score().attach(engine, \"r2\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6449f0c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "def train_model(\n",
    "    resume: bool = True,\n",
    "    delete_previous_model_dir: bool = False,\n",
    "    num_epochs: int = 50,\n",
    "    batch_size: int = 1,\n",
    "    learning_rate: float = 1e-4,\n",
    "    accumulation_steps: int = 32,\n",
    "    early_stopping_patience: int = 5,\n",
    "    model_dir: str = \"./model_dir\",\n",
    "\n",
    "    # Dataset configuration\n",
    "    training_set_size: int = None,\n",
    "    validation_set_size: int = None,\n",
    "    train_ids_txt: str = \"../dataset/raw/subset_dir/train_design_ids.txt\",\n",
    "    val_ids_txt: str = \"../dataset/raw/subset_dir/val_design_ids.txt\",\n",
    "    raw_npy_dir: str = \"../dataset/processed/slices\",\n",
    "    csv_path: str = \"../dataset/raw/DrivAerNetPlusPlus_Drag_8k_cleaned.csv\",\n",
    "    cd_scaler=None,\n",
    "    point_scaler=None, \n",
    "\n",
    "    # # Model hyperparameters (Hyperparameter for EdgeConv) ---\n",
    "    k_neighbors: int = 25,\n",
    "    slice_embedding_dim: int = 256,\n",
    "    transformer_hidden_dim: int = 256,\n",
    "    transformer_num_layers: int = 2,\n",
    "    transformer_nhead: int = 1,\n",
    "    cd_regressor_input_dim: int = 256,\n",
    "):\n",
    "    checkpoints_dir = os.path.join(model_dir, \"checkpoints\")\n",
    "    results_dir = os.path.join(model_dir, \"results\")\n",
    "    os.makedirs(checkpoints_dir, exist_ok=True)\n",
    "    os.makedirs(results_dir, exist_ok=True)\n",
    "\n",
    "    # 1) Optional cleanup\n",
    "    if delete_previous_model_dir and not resume:\n",
    "        if os.path.isdir(model_dir) and os.listdir(model_dir):\n",
    "            confirm = input(f\"[WARN] Contents found in '{model_dir}'. Delete all contents? (yes/no): \").strip().lower()\n",
    "            if confirm == \"yes\":\n",
    "                # Delete all contents inside model_dir\n",
    "                for entry in os.scandir(model_dir):\n",
    "                    if entry.is_dir():\n",
    "                        shutil.rmtree(entry.path)\n",
    "                    else:\n",
    "                        os.remove(entry.path)\n",
    "                print(f\"[INFO] All contents of '{model_dir}' have been deleted.\")\n",
    "            else:\n",
    "                print(\"[INFO] Cleanup aborted by user.\")\n",
    "        else:\n",
    "            print(f\"[INFO] Nothing to clean. '{model_dir}' is empty or does not exist.\")\n",
    "\n",
    "\n",
    "    # 2) Model setup\n",
    "    \n",
    "    # --- MODIFIED: Model setup ---\n",
    "    print(f\"[INFO] Setting up model with k={k_neighbors} for EdgeConv...\")\n",
    "    slice_encoder = EdgeConvSliceEncoder(input_dim=2, emb_dim=slice_embedding_dim, k=k_neighbors)\n",
    "    encoder = TransformerSliceEncoder(input_dim=slice_embedding_dim, hidden_dim=transformer_hidden_dim, num_layers=transformer_num_layers, nhead=transformer_nhead)\n",
    "    regressor = CdRegressor(input_dim=cd_regressor_input_dim)\n",
    "    model = CdPredictorNet(slice_encoder, encoder, regressor).to(device)\n",
    "\n",
    "\n",
    "    print(model)\n",
    "    print(f\"[INFO] Total trainable parameters: {sum(p.numel() for p in model.parameters() if p.requires_grad):,}\")\n",
    "\n",
    "    # 3) Training components\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)    \n",
    "    loss_fn = nn.SmoothL1Loss()\n",
    "    trainer = create_trainer(model, optimizer, loss_fn, device, accumulation_steps)\n",
    "    evaluator = create_evaluator(model, loss_fn, device)\n",
    "    attach_metrics(trainer, loss_fn)\n",
    "    attach_metrics(evaluator, loss_fn)\n",
    "\n",
    "    train_pbar = ProgressBar(persist=True, desc=\"Training\")\n",
    "    train_pbar.attach(trainer, metric_names=[\"loss\", \"rmse\", \"r2\"])\n",
    "    val_pbar = ProgressBar(persist=True, desc=\"Validation\")\n",
    "    val_pbar.attach(evaluator, metric_names=[\"loss\", \"rmse\", \"r2\"])\n",
    "\n",
    "    # 4) Data setup ---\n",
    "    print(f\"[INFO] Loading data from raw npy directory: {raw_npy_dir}\")\n",
    "    train_dataset = CarSlicesDataset_PyG(train_ids_txt, raw_npy_dir, csv_path, cd_scaler, point_scaler, training_set_size)\n",
    "    val_dataset = CarSlicesDataset_PyG(val_ids_txt, raw_npy_dir, csv_path, cd_scaler, point_scaler, validation_set_size)\n",
    "\n",
    "    train_loader = PyGDataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True,\n",
    "        collate_fn=collate_fn_pyg,\n",
    "    )\n",
    "    val_loader = PyGDataLoader(\n",
    "        val_dataset,\n",
    "        batch_size=batch_size * 2,\n",
    "        shuffle=False,\n",
    "        collate_fn=collate_fn_pyg,\n",
    "    )\n",
    "\n",
    "    # 5) Resume\n",
    "    start_epoch = 1\n",
    "    if resume:\n",
    "        ckpts = sorted(glob.glob(os.path.join(checkpoints_dir, \"epoch_*.pt\")))\n",
    "        if ckpts:\n",
    "            last_ckpt = ckpts[-1]\n",
    "            print(f\"[INFO] Resuming from checkpoint: {os.path.basename(last_ckpt)}\")\n",
    "            data = torch.load(last_ckpt, map_location=device)\n",
    "            model.load_state_dict(data[\"model\"])\n",
    "            optimizer.load_state_dict(data[\"optimizer\"])\n",
    "            start_epoch = data.get(\"epoch\", 1) + 1\n",
    "        else:\n",
    "            print(\"[INFO] No checkpoint found. Starting fresh.\")\n",
    "\n",
    "    # 6) TensorBoard\n",
    "    tb_writer = SummaryWriter(log_dir=os.path.join(checkpoints_dir, \"logs\"), purge_step=start_epoch - 1)\n",
    "\n",
    "    # 7) Best model saving\n",
    "    evaluator.add_event_handler(Events.COMPLETED, ModelCheckpoint(\n",
    "        dirname=checkpoints_dir,\n",
    "        filename_prefix=\"best_model\",\n",
    "        n_saved=1,\n",
    "        score_function=lambda eng: eng.state.metrics[\"r2\"],\n",
    "        score_name=\"r2\",\n",
    "        global_step_transform=lambda eng, _: eng.state.epoch + start_epoch - 1,\n",
    "        require_empty=False\n",
    "    ), {\"model\": model})\n",
    "\n",
    "    # 8) Early stopping\n",
    "    evaluator.add_event_handler(Events.COMPLETED, EarlyStopping(\n",
    "        patience=early_stopping_patience,\n",
    "        score_function=lambda eng: eng.state.metrics[\"r2\"],\n",
    "        trainer=trainer\n",
    "    ))\n",
    "\n",
    "    # 9) Load previous history if exists\n",
    "    history_path = os.path.join(results_dir, \"training_history.json\")\n",
    "    new_history = []\n",
    "    if os.path.exists(history_path):\n",
    "        with open(history_path, \"r\") as f:\n",
    "            new_history = json.load(f)\n",
    "    else:\n",
    "        # Create the directory if it doesn't exist\n",
    "        os.makedirs(os.path.dirname(history_path), exist_ok=True)\n",
    "\n",
    "    # 10) Validation handler\n",
    "    @trainer.on(Events.EPOCH_COMPLETED)\n",
    "    def validate(engine):\n",
    "        evaluator.run(val_loader)\n",
    "        epoch_num = engine.state.epoch + start_epoch - 1\n",
    "        train_metrics = engine.state.metrics\n",
    "        val_metrics = evaluator.state.metrics\n",
    "    \n",
    "    # 11) Record and log metrics and save history \n",
    "        record = {\n",
    "            \"epoch\": epoch_num,\n",
    "            \"Train_loss\": train_metrics[\"loss\"],\n",
    "            \"Train_rmse\": train_metrics[\"rmse\"],\n",
    "            \"Train_r2\": train_metrics[\"r2\"],\n",
    "            \"Val_loss\": val_metrics[\"loss\"],\n",
    "            \"Val_rmse\": val_metrics[\"rmse\"],\n",
    "            \"Val_r2\": val_metrics[\"r2\"],\n",
    "        }\n",
    "        new_history.append(record)\n",
    "\n",
    "        tb_writer.add_scalars(\"Loss\", {\n",
    "            \"Train\": train_metrics[\"loss\"],\n",
    "            \"Validation\": val_metrics[\"loss\"]\n",
    "        }, epoch_num)\n",
    "        tb_writer.add_scalars(\"RMSE\", {\n",
    "            \"Train\": train_metrics[\"rmse\"],\n",
    "            \"Validation\": val_metrics[\"rmse\"]\n",
    "        }, epoch_num)\n",
    "        tb_writer.add_scalars(\"R2\", {\n",
    "            \"Train\": train_metrics[\"r2\"],\n",
    "            \"Validation\": val_metrics[\"r2\"]\n",
    "        }, epoch_num)\n",
    "\n",
    "        print(f\"\\n[Epoch {epoch_num:03d}] ------------------------\")\n",
    "        for key, value in record.items():\n",
    "            if key != \"epoch\":\n",
    "                print(f\"{key:17}: {value:.6f}\" if isinstance(value, float) else f\"{key:17}: {value}\")\n",
    "\n",
    "        with open(history_path + \".bak\", \"w\") as f:\n",
    "            json.dump(new_history, f, indent=2)\n",
    "        with open(history_path, \"w\") as f:\n",
    "            json.dump(new_history, f, indent=2)\n",
    "\n",
    "        torch.save({\n",
    "            \"epoch\": epoch_num,\n",
    "            \"model\": model.state_dict(),\n",
    "            \"optimizer\": optimizer.state_dict()\n",
    "        }, os.path.join(checkpoints_dir, f\"epoch_{epoch_num:03d}_loss_{val_metrics['loss']:.8f}.pt\"))\n",
    "\n",
    "    # 11) Run training\n",
    "    try:\n",
    "        trainer.run(train_loader, max_epochs=num_epochs - start_epoch + 1)\n",
    "    except KeyboardInterrupt:\n",
    "        print(\"\\n⛔ Training interrupted by user.\")\n",
    "    finally:\n",
    "        tb_writer.close()\n",
    "        best_ckpt = sorted(glob.glob(os.path.join(checkpoints_dir, \"best_model_*.pt\")))\n",
    "        if best_ckpt:\n",
    "            print(f\"[INFO] Loading best model from: {os.path.basename(best_ckpt[-1])}\")\n",
    "            best_model_data = torch.load(best_ckpt[-1], map_location=device)\n",
    "            model.load_state_dict(best_model_data[\"model\"] if \"model\" in best_model_data else best_model_data)\n",
    "\n",
    "        with open(history_path, \"r\") as f:\n",
    "            final_history = json.load(f)\n",
    "        return model, final_history\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "956f8fb3",
   "metadata": {},
   "source": [
    "# Training Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8541b5f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] All contents of '../model_outputs/DTM256_Model' have been deleted.\n",
      "[INFO] Setting up model with k=16 for EdgeConv...\n",
      "CdPredictorNet(\n",
      "  (slice_encoder): EdgeConvSliceEncoder(\n",
      "    (edge_conv): EdgeConv(nn=Sequential(\n",
      "      (0): Linear(in_features=4, out_features=64, bias=True)\n",
      "      (1): ReLU()\n",
      "      (2): Linear(in_features=64, out_features=128, bias=True)\n",
      "      (3): ReLU()\n",
      "      (4): Linear(in_features=128, out_features=512, bias=True)\n",
      "    ))\n",
      "  )\n",
      "  (transformer_encoder): TransformerSliceEncoder(\n",
      "    (transformer): TransformerEncoder(\n",
      "      (layers): ModuleList(\n",
      "        (0-3): 4 x TransformerEncoderLayer(\n",
      "          (self_attn): MultiheadAttention(\n",
      "            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
      "          )\n",
      "          (linear1): Linear(in_features=512, out_features=1024, bias=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (linear2): Linear(in_features=1024, out_features=512, bias=True)\n",
      "          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout1): Dropout(p=0.1, inplace=False)\n",
      "          (dropout2): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (attn_pool): Linear(in_features=512, out_features=1, bias=True)\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      "  (regressor): CdRegressor(\n",
      "    (net): Sequential(\n",
      "      (0): Linear(in_features=512, out_features=256, bias=True)\n",
      "      (1): ReLU()\n",
      "      (2): Linear(in_features=256, out_features=128, bias=True)\n",
      "      (3): ReLU()\n",
      "      (4): Linear(in_features=128, out_features=1, bias=True)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "[INFO] Total trainable parameters: 8,650,690\n",
      "[INFO] Loading data from raw npy directory: ../dataset/processed/slices\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training [1/100]: [50/50] 100%|██████████ [01:02<00:00]\n",
      "Validation: [5/5] 100%|██████████ [00:06<00:00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Epoch 001] ------------------------\n",
      "Train_loss       : 0.338851\n",
      "Train_rmse       : 0.849382\n",
      "Train_r2         : -1.176519\n",
      "Val_loss         : 0.246254\n",
      "Val_rmse         : 0.713952\n",
      "Val_r2           : -0.231510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training [2/100]: [50/50] 100%|██████████, loss=0.339, rmse=0.849, r2=-1.18 [01:02<00:00]\n",
      "Validation: [5/5] 100%|██████████, loss=0.246, rmse=0.714, r2=-0.232 [00:06<00:00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Epoch 002] ------------------------\n",
      "Train_loss       : 0.209280\n",
      "Train_rmse       : 0.653183\n",
      "Train_r2         : -0.287138\n",
      "Val_loss         : 0.205649\n",
      "Val_rmse         : 0.644224\n",
      "Val_r2           : -0.002707\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training [3/100]: [50/50] 100%|██████████, loss=0.209, rmse=0.653, r2=-0.287 [01:03<00:00]\n",
      "Validation: [5/5] 100%|██████████, loss=0.206, rmse=0.644, r2=-0.00271 [00:06<00:00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Epoch 003] ------------------------\n",
      "Train_loss       : 0.169780\n",
      "Train_rmse       : 0.585195\n",
      "Train_r2         : -0.033134\n",
      "Val_loss         : 0.210552\n",
      "Val_rmse         : 0.651992\n",
      "Val_r2           : -0.027035\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training [4/100]: [50/50] 100%|██████████, loss=0.17, rmse=0.585, r2=-0.0331 [01:03<00:00]\n",
      "Validation: [5/5] 100%|██████████, loss=0.211, rmse=0.652, r2=-0.027 [00:06<00:00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Epoch 004] ------------------------\n",
      "Train_loss       : 0.164790\n",
      "Train_rmse       : 0.577234\n",
      "Train_r2         : -0.005217\n",
      "Val_loss         : 0.220380\n",
      "Val_rmse         : 0.668546\n",
      "Val_r2           : -0.079849\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training [5/100]: [50/50] 100%|██████████, loss=0.165, rmse=0.577, r2=-0.00522 [01:03<00:00]\n",
      "Validation: [5/5] 100%|██████████, loss=0.22, rmse=0.669, r2=-0.0798 [00:06<00:00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Epoch 005] ------------------------\n",
      "Train_loss       : 0.165653\n",
      "Train_rmse       : 0.579109\n",
      "Train_r2         : -0.011757\n",
      "Val_loss         : 0.217779\n",
      "Val_rmse         : 0.664140\n",
      "Val_r2           : -0.065661\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training [6/100]: [50/50] 100%|██████████, loss=0.166, rmse=0.579, r2=-0.0118 [01:03<00:00]\n",
      "Validation: [5/5] 100%|██████████, loss=0.218, rmse=0.664, r2=-0.0657 [00:06<00:00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Epoch 006] ------------------------\n",
      "Train_loss       : 0.164339\n",
      "Train_rmse       : 0.576434\n",
      "Train_r2         : -0.002433\n",
      "Val_loss         : 0.211875\n",
      "Val_rmse         : 0.654203\n",
      "Val_r2           : -0.034012\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training [7/100]: [50/50] 100%|██████████, loss=0.164, rmse=0.576, r2=-0.00243 [01:03<00:00]\n",
      "Validation: [5/5] 100%|██████████, loss=0.212, rmse=0.654, r2=-0.034 [00:06<00:00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Epoch 007] ------------------------\n",
      "Train_loss       : 0.163586\n",
      "Train_rmse       : 0.574891\n",
      "Train_r2         : 0.002928\n",
      "Val_loss         : 0.212968\n",
      "Val_rmse         : 0.656036\n",
      "Val_r2           : -0.039813\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training [8/100]: [50/50] 100%|██████████, loss=0.164, rmse=0.575, r2=0.00293 [01:02<00:00]\n",
      "Validation: [5/5] 100%|██████████, loss=0.213, rmse=0.656, r2=-0.0398 [00:06<00:00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Epoch 008] ------------------------\n",
      "Train_loss       : 0.165637\n",
      "Train_rmse       : 0.578539\n",
      "Train_r2         : -0.009766\n",
      "Val_loss         : 0.211217\n",
      "Val_rmse         : 0.653107\n",
      "Val_r2           : -0.030548\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training [9/100]: [50/50] 100%|██████████, loss=0.166, rmse=0.579, r2=-0.00977 [01:02<00:00]\n",
      "Validation: [5/5] 100%|██████████, loss=0.211, rmse=0.653, r2=-0.0305 [00:06<00:00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Epoch 009] ------------------------\n",
      "Train_loss       : 0.163033\n",
      "Train_rmse       : 0.574039\n",
      "Train_r2         : 0.005879\n",
      "Val_loss         : 0.212790\n",
      "Val_rmse         : 0.655740\n",
      "Val_r2           : -0.038876\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training [10/100]: [50/50] 100%|██████████, loss=0.163, rmse=0.574, r2=0.00588 [01:03<00:00]\n",
      "Validation: [5/5] 100%|██████████, loss=0.213, rmse=0.656, r2=-0.0389 [00:06<00:00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Epoch 010] ------------------------\n",
      "Train_loss       : 0.163834\n",
      "Train_rmse       : 0.575271\n",
      "Train_r2         : 0.001608\n",
      "Val_loss         : 0.215264\n",
      "Val_rmse         : 0.659896\n",
      "Val_r2           : -0.052086\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training [11/100]: [50/50] 100%|██████████, loss=0.164, rmse=0.575, r2=0.00161 [01:02<00:00]\n",
      "Validation: [5/5] 100%|██████████, loss=0.215, rmse=0.66, r2=-0.0521 [00:06<00:00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Epoch 011] ------------------------\n",
      "Train_loss       : 0.165190\n",
      "Train_rmse       : 0.578180\n",
      "Train_r2         : -0.008513\n",
      "Val_loss         : 0.213649\n",
      "Val_rmse         : 0.657179\n",
      "Val_r2           : -0.043441\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training [12/100]: [50/50] 100%|██████████, loss=0.165, rmse=0.578, r2=-0.00851 [01:03<00:00]\n",
      "Validation: [5/5] 100%|██████████, loss=0.214, rmse=0.657, r2=-0.0434 [00:06<00:00]\n",
      "2025-07-09 12:36:36,030 ignite.handlers.early_stopping.EarlyStopping INFO: EarlyStopping: Stop training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Epoch 012] ------------------------\n",
      "Train_loss       : 0.165699\n",
      "Train_rmse       : 0.578690\n",
      "Train_r2         : -0.010294\n",
      "Val_loss         : 0.212938\n",
      "Val_rmse         : 0.655989\n",
      "Val_r2           : -0.039664\n",
      "[INFO] Loading best model from: best_model_model_1_r2=-0.0027.pt\n",
      "   epoch  Train_loss  Train_rmse  Train_r2  Val_loss  Val_rmse    Val_r2\n",
      "0      1    0.338851    0.849382 -1.176519  0.246254  0.713952 -0.231510\n",
      "1      2    0.209280    0.653183 -0.287138  0.205649  0.644224 -0.002707\n",
      "2      3    0.169780    0.585195 -0.033134  0.210552  0.651992 -0.027035\n",
      "3      4    0.164790    0.577234 -0.005217  0.220380  0.668546 -0.079849\n",
      "4      5    0.165653    0.579109 -0.011757  0.217779  0.664140 -0.065661\n"
     ]
    }
   ],
   "source": [
    "# Directories\n",
    "model_dir = \"../model_outputs/DTM256_Model\"\n",
    "checkpoints_dir = os.path.join(model_dir, \"checkpoints\")\n",
    "results_dir = os.path.join(model_dir, \"results\")\n",
    "os.makedirs(checkpoints_dir, exist_ok=True)\n",
    "os.makedirs(results_dir, exist_ok=True)\n",
    "\n",
    "# History file paths\n",
    "json_history_path = os.path.join(results_dir, \"training_history.json\")\n",
    "\n",
    "# Call the training function\n",
    "model, _ = train_model(\n",
    "    # General training configuration\n",
    "    resume=False,\n",
    "    delete_previous_model_dir=True,\n",
    "    num_epochs=100,\n",
    "    batch_size=4,\n",
    "    learning_rate=1e-5,\n",
    "    accumulation_steps=4,\n",
    "    early_stopping_patience= 10,\n",
    "    model_dir = model_dir,\n",
    "\n",
    "    # Dataset configuration\n",
    "    training_set_size = 200,\n",
    "    validation_set_size = 40,\n",
    "    train_ids_txt=\"../dataset/raw/subset_dir/train_design_ids.txt\",\n",
    "    val_ids_txt=\"../dataset/raw/subset_dir/val_design_ids.txt\",\n",
    "    raw_npy_dir = \"../dataset/processed/slices\",\n",
    "    csv_path  = \"../dataset/raw/DrivAerNetPlusPlus_Drag_8k_cleaned.csv\",\n",
    "    cd_scaler=cd_scaler,\n",
    "    point_scaler=point_scaler, \n",
    "\n",
    "    # --- MODIFIED: Model hyperparameters ---\n",
    "    k_neighbors=16, \n",
    "    slice_embedding_dim = 512,\n",
    "    transformer_hidden_dim = 512,\n",
    "    transformer_num_layers = 4,\n",
    "    transformer_nhead = 4, # A good starting point\n",
    "    cd_regressor_input_dim= 512,\n",
    ")\n",
    "\n",
    "# Load Json history and convert to DataFrame and print\n",
    "history_df = pd.read_json(json_history_path)\n",
    "print(history_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92070095",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
